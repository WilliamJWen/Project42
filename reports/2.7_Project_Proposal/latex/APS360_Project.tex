\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
\usepackage{graphicx}
\usepackage{hyperref}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Proposal}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{42}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

%######## APS360: Put your project Title here
\title{Project Proposal}


%######## APS360: Put your names, student IDs and Emails here
\author{Vedansh Mehta  \\
Student\# 1008973577 \\
\texttt{vedansh.mehta@mail.utoronto.ca} \\
\And
Nathan Shreve  \\
Student\# 1004404487 \\
\texttt{n.shreve@mail.utoronto.ca} \\
\AND
William Wen  \\
Student\# 1007956650 \\
\texttt{jwilliam.wen@mail.utoronto.ca} \\
\And
Paul Zhao \\
Student\# 1009052276 \\
\texttt{paul.zhao@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 
%######## APS360: Document starts here
\begin{document}


\maketitle

\begin{abstract}
This project aims to develop a deep learning model for detecting AI-generated images. Our two-step approach first trains a Convolutional Neural Network (CNN) on real images to learn natural image statistics, then classifies real and synthetic images based on loss metrics from the CNN's output. By leveraging zero-shot learning in the first step, our model adapts to new AI-generation techniques without frequent retraining. This work aims to support media verification, misinformation detection, and digital security.
%######## APS360: Do not change the next line. This shows your Main body page count.
----Total Pages: \pageref{last_page}
\end{abstract}



\section{Introduction}
\label{intro}
% Comments (Nathan):
% We decided not to use the term deep fake, right?
% We need citations for all our claims

The emergence of photorealistic artificial intelligence (AI) image generation presents a significant challenge in the current digital landscape. This technology has evolved from simple image modifications to sophisticated videos that can convincingly mimic real individuals \citep{cnn2025}. With tools like Generative Adversarial Networks (GANs) and Diffusion Models (DMs), even non-experts can now generate convincing synthetic media. These media are often indistinguishable from authentic content, even to those with specialized knowledge.

\subsection{Motivation}
% Comment (Nathan): Cite, don't use "deep fake"
The rising prevalence of AI image generation applications presents significant dangers to societal trust, individual safety, and the integrity of information \citep{epstein2023generative}. AI image generation has been used to spread misinformation, sway political debates, and jeopardize individual reputations \citep{chesney2019}. It is also responsible for blurring the line between art made by humans and that produced by AI, challenging traditional concepts of authorship and artistic authenticity \citep{Dipascalido2023}. Hence, there is a broad need to accurately identify AI-generated media.

\subsection{Goal}
The aim of this project is to create a reliable deep learning model that can distinguish AI-generated images from real ones, aiding the larger initiative against digital misinformation. While we will focus on AI-based images, our approach can be extended to video evaluation.

\subsection{Significance}
% Comment (Nathan): This feels like it's the same thing as the Motivation, just with different examples
AI-generated image detection is significant to many fields such as journalism, social media networks, and cybersecurity. With the rising accessibility of ``deep fake'' creation tools, the potential for their misuse increases. The creation of efficient detection systems is vital not only for spotting counterfeit content, but also for rebuilding public trust in digital media. News agencies can employ detection tools to question the authenticity of online media \citep{Kumarage2023}, whereas social media sites can utilize them to identify and then handle altered content \citep{clickinsights2023}.

\subsection{Justification for Employing Deep Learning}
% Comment (Nathan):
% Again, citations
% AI conflict?
% We say later that CNNs don't work all too well. You say that detection systems need to utilize recent developments to anticipate new threats -- (a) what does this mean?, (b) the point of doing zero-shot is that we don't have to continually adapt to new generative models coming out
% You talk about transfer learning but we aren't using that
The idea is to fight AI with AI. Deep learning is highly effective for the purpose of detecting AI-generated images because conventional image recognition techniques depend solely on manually crafted features, which cannot grasp the subtle and complex artifacts created during the image generation process. Therefore, detection systems need to be flexible and utilize recent developments in technology, implying the need for deep learning \citep{ledig2017}.

\section{Illustration}
\label{illustration}
Figure~\ref{fig:high-level-architecture} illustrates our two-step high-level architecture for AI-generated image detection. More details are provided in Section~\ref{sec:architecture}.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{Fig/high_level_architecture.pdf}
    \caption{Two-step high level architecture for AI-generated image detection. Step 1 (top) trains a compression and reconstruction model (blue box) solely on real images, which downscales high-resolution images using an average pooling, and learn to reconstruct the high resolution image using convolutional layers and logistic probability distribution parameters. Step 2 (bottom) applies the trained model (blue box) to both real and AI-generated images, extracting entropy-based statistics such as Negative Log-Likelihood (NLL) and entropy values. These statistics are passed through multiple fully connected layers for final classification.}
    \label{fig:high-level-architecture}
\end{figure}

\section{Background \& Related Work}
\label{background}

Image synthesis is the process wherein an artificial image is generated by a computer from an input prompt, which may be text or some other form of media. This field exploded after the creation of GANs in 2014, a deep learning architecture particularly adept at generating photorealistic images \citep{GANfather}. More recently, DMs have also been a popular choice for image synthesis \citep{latent-diffusion}. While many attempts have been made to develop programs that can detect images generated by these architectures, they continually evolve to outsmart old detectors.

\subsection{Sightengine}

There are a number of AI-generated image detection websites which are free to use. One of these is \citet{sightengine}, which has a high accuracy rate compared to many other websites: approximately 99\% on real images and 81\% on AI-generated ones \citep{li2024adversarialaiartunderstandinggeneration}. However, it is far from foolproof. For example, when tested on images generated from image prompts by Dream Studio and DALL-E, its accuracy falls to only 34\%. As opposed to images generated from text promts, images generated from real image prompts may be more challenging to detect, since they are more likely to be very similar to the real images they were generated from.

Many free websites like sightengine also predict the source of AI-generated images among many commonly-used synthesis models. Although the accuracy of this feature has not been formally investigated, it seems to fail often.

Though sightengine has not published its methods for AI-generated image detection, there are a number of open-source detectors available online, some of which are discussed below.

\subsection{Beyond the Spectrum}

Many earlier attempts at AI-generated image detection focused on GAN-generated images, since using DMs for image synthesis only began in 2022. One of these is Beyond the Spectrum (BtS), an open-source project \citep{he2021spectrumdetectingdeepfakesresynthesis}.

Its method for detection involves two stages. First, a re-synthesizer is trained, only on real images, to reconstruct images from their downsampled versions. Next, this re-synthesizer is given both real and fake images, and the reconstruction error (which is assumed to be greater for GAN-generated images) is given to a classifier to predict whether a given image is real or not.

In 2021, BtS achieved approxiately 90\% accuracy on its testing datasets and was state-of-the-art (SoTA). However, in 2024, after the progression of GAN models and the advent of DMs, BtS achieves only a 21\% accuracy rate \citep{li2024adversarialaiartunderstandinggeneration}. Nonetheless, its approach is echoed in more recent successful approaches, such as the zero-shot method discussed in \ref{ZED}.

\subsection{Contrastive Language–Image Pretraining}

Another architecture that has been explored for detecting AI-generated images is Contrastive Language–Image Pretraining (CLIP), which was developed by OpenAI in 2021 \citep{radford2021learningtransferablevisualmodels}. This model is trained on pairs of images and text, and in the context of AI-generated image detection, this text might either be their prompts or human-written descriptions. CLIP was used to achieve an accuracy of 95-100\%, making it a promising model for AI-generated image detection \citep{moskowitz2024detectingaigeneratedimagesclip}.

\subsection{Vision Transformers}

In natural language processing, text is interpreted as a sequence of tokens from which subsequent tokens can be predicted. Vision transformers (ViT) take a similar approach. Images are broken down into non-overlapping sections, like tokens, which are sent into an encoder comprised of multi-head attention and feed-forward neural networks. The output of the encoder is then passed into an MLP which classifies the image; in our case, it predicts whether the image is real or fake. In April 2024, researchers combined CLIP and ViT (CLIP-ViT) and were able to outperform a number of SoTA detection methods with an average accuracy of 90\% \citep{cozzolino2024raisingbaraigeneratedimage}.

\subsection{Zero-Shot Entropy-Based Detector}
\label{ZED}

The main issue in designing AI-generated image detectors is that image synthesis models are constantly evolving to circumvent detectors trained on old data. In September 2024, a new zero-shot method was devised which initally only trains on real images \citep{cozzolino2024zeroshotdetectionaigeneratedimages}. First, a CNN is trained to predict real images from encoded versions of those images. Next, the CNN is used to predict both real and fake images from their encoded versions, and loss statistics used to differentiate real images from synthetic ones. Higher loss generally corresponds to AI-generated images, since the CNN provides a good model for real images.

This method was able to achieve an accuracy of 90\%, better than many other SoTA models. However, one drawback is that training and testing datasets were comprised only of uncompressed images.

\section{Data Processing}
\label{data}
Our model involves two phases of training (see \ref{arch}). As such, we require five datasets: two training sets, two validation sets, and one testing set. The first phase is trained only on real images, meaning that one training set and one validation set will be comprised only of real images. For the other training and validation sets, it is crucial to process data in order to minimize bias. We have identified the most potentially impactful bias in our data as being the semantic content of the images.

\subsection{Data Collection and Organization}
\label{data_coll}
To guarantee that the model is exposed to a diverse range of semantics, we will utilize two well-established camera-based digital forensics datasets: (1) RAISE \citep{10.1145/2713168.2713194} and (2) the Dresden Image Database \citep{10.1145/1774088.1774427}. These datasets collectively contain approximately 22k real images, captured under varying conditions and environments. We will select synthetic images from three sources: \citet{wang2020cnngeneratedimagessurprisinglyeasy}, \citet{corvi2022detectionsyntheticimagesgenerated}, and \citet{ojha2024universalfakeimagedetectors}, which contain images generated from a variety of GANs and DMs. The number of images in these sets total over 22k, so we will select a subsection of them that (a) matches the semantic content of the 22k real images and (b) represents a variety of AI-generation architectures, ensuring the model's ability to generalize.

The model will be trained in two phases, described in \ref{arch}. The division of data across each phase is detailed in Table \ref{data_splits}.

    \begin{table}[t]
    \caption{Data splits.}
    \label{data_splits}
    \begin{center}
    \begin{tabular}{llll}
    \multicolumn{1}{c}{\bf Phase / Split} & \multicolumn{1}{c}{\bf Num. Real Images}    & \multicolumn{1}{c}{\bf Num. Synthetic Images} & \multicolumn{1}{c}{\bf Num. Total Images}
    \\ \hline \\
    Step 1 / Training       & 10k   & 0     & 10k \\
    Step 1 / Validation     & 2k    & 0     & 2k \\
    Step 2 / Training       & 5k    & 5k    & 10k \\
    Step 2 / Validation     & 1k    & 1k    & 2k \\
    Testing                 & 2k    & 2k    & 4k \\             
    \end{tabular}
    \end{center}
    \end{table}

\subsection{Data Modification}
\label{data_mod}
For image inputs, the CNN requires a fixed resolution of 256×256 pixels. Most images in the datasets we are using are aleady 256×256. However, if we need to use images of larger sizes, they will be cropped to 256×256 while preserving their essential features. We must ensure that all images are uncompressed so that our CNN will properly represent real images.

To prevent any biases arising from variations in image attributes, all datasets will be normalized and standardized. This includes converting all images to RGB color space, ensuring uniform channel distributions across the dataset. Standardizing the color format enhances consistency in feature representation, improving the model's robustness and generalization.

\section{Architecture}
\label{arch}
\subsection{Motivation}

Nowadays, image classification models typically use CNNs as their base architecture. Classical CNNs train on datasets of AI-generated images to learn special features that are otherwise undetectable. However, as more and more image generation models are released, these CNNs are routinely oustmarted. New image generation models carry new characteristics which the CNN never learned. This creates a need for further training with new datasets, which takes both time and money \citep{cozzolino2024zeroshotdetectionaigeneratedimages}.

Our approach is unique in that the first phase of our model's training process doesn't rely on synthetic data sets. The idea behind this approach is to estimate how ``surprising'' an image is compared to the model of real images that the CNN provides.

\subsection{Detailed Architecture}
\label{sec:architecture}

% Training the architecture of our neural network consists of two phases: (1) CNN training and (2) loss-based classification.
Our proposed model follows a two-step training process: (1) CNN training and (2) loss-based classification.

\subsubsection{Step 1: Real Image Compression and Reconstruction}
% In stage (1), WILLIAM ADD HERE the downsized versions of real images are given to a CNN as inputs. The CNN will upscale these images and predict their original full-sized versions.  
% Comments (Nathan):
% The model doesn't learn to downscale the images, I think this is just done through average pooling
% Use \ref{}s to reference your figure
The first step, illustrated in Figure \ref{fig:high-level-architecture}, involves training an image compression and reconstruction model \textbf{solely on real images}. The model downscales and then learns to reconstruct high-resolution images using pooling operations and convolutional layers. Specifically:
\begin{itemize}
    \item Real high-resolution images are downscaled through pooling layers and passed to a multi-layered CNN as inputs.
    \item The CNN extracts essential features, maps them to a latent space representation, upscales them, and connects to a fully connected layer.
    \item The fully connected layer then predicts the \textbf{weight, mean, and scale} parameters for logistic probability distributions, which are used to reconstruct the original high-resolution image.
    \item The loss will be used to adjust the weights and biases of the CNN's filters through backpropagation.
\end{itemize}

This first stage is zero-shot, meaning it will not require retraining on synthetic data upon the advent of new image-generating AI models. Furthermore, the CNN will be able to capture statistical features that only real images share. 

\subsubsection{Step 2: Real vs. AI-Generated Image Classification}
% Suggestion (Nathan):
% In stage (2), we no longer train the CNN, and it will provide a good model for upscaling real images, but not AI-generated ones. In this stage, we will give the CNN both real and generated images. We will calculate loss statistics on its output, and use these statistics as the input to a classifier. SOME CONCLUSION HERE
In the second step, illustrated in Figure \ref{fig:high-level-architecture}, the model is extended to classify images as real or AI-generated. This stage leverages both real and AI-generated datasets:
\begin{itemize}
    \item Input images, including both real and AI-generated high-resolution images, undergo the same downscaling and reconstruction process as in Step 1.
    \item Using the obtained \textbf{mean, weight, and scale} parameters, the model computes loss statistics such as \textbf{Negative Log-Likelihood (NLL) and entropy values} for each image.
    \item These computed statistics are then passed through multiple fully connected layers to classify whether an image is real or AI-generated.
    \item Using input image labels as either real or synthetic and binary cross entropy loss, the fully connected layers will be trained using backpropagation.
\end{itemize}

This second stage builds on top of CNN's ability to accurately reconstruct real images learned in the first step, and learns to utilize nuances between their loss statistics to perform classification. 

By structuring the model in this two-step process, we ensure that the first stage learns an accurate representation of natural image statistics, which the second stage leverages to effectively detect synthetic images.

\section{Baseline Model}
\label{baseline}

Our baseline model will mirror \citet{wang2020cnngeneratedimagessurprisinglyeasy}, an early attempt at AI-generated image detection. This model uses ResNet-50 trained on real images from ImageNet and fake images generated by three GAN architecures. We will expand our dataset to include fake images from a greater variety of image generators, including diffusion models (see \ref{data}).

We will not use ResNet-50 due to its complexity. Instead, we will implement our own ResNet-inspired 10-layer CNN as detailed in Table \ref{baseline_arch}.

    \begin{table}[t]
    \caption{Baseline model architecture: convolutional layers}
    \label{baseline_arch}
    \begin{center}
    \begin{tabular}{llllll}
    \multicolumn{1}{c}{\bf Convolution Layer}   & \multicolumn{1}{c}{\bf Kernel Size}   & \multicolumn{1}{c}{\bf Padding}    & \multicolumn{1}{c}{\bf Stride}   & \multicolumn{1}{c}{\bf Channels}   & \multicolumn{1}{c}{\bf Dimensions}
    \\ \hline \\
    Input               & N/A   & N/A   & N/A   & 3     & 256×256 \\
    Conv. 1             & 7×7   & 3     & 2     & 64    & 128×128 \\
    Average pooling     & 2×2   & 0     & 2     & 64    & 64×64 \\
    Conv. 2             & 3×3   & 1     & 1     & 64    & 64×64 \\
    Conv. 3             & 3×3   & 1     & 1     & 64    & 64×64 \\
    Conv. 4             & 3×3   & 1     & 2     & 128   & 32×32 \\
    Conv. 5             & 3×3   & 1     & 1     & 128   & 32×32 \\
    Conv. 6             & 3×3   & 1     & 2     & 256   & 16×16 \\
    Conv. 7             & 3×3   & 1     & 1     & 256   & 16×16 \\
    Conv. 8             & 3×3   & 1     & 2     & 512   & 8×8 \\
    Conv. 9             & 3×3   & 1     & 1     & 512   & 8×8 \\
    Average pooling     & 4×4   & 0     & 2     & 512   & 2×2 \\
    \end{tabular}
    \end{center}
    \end{table}

Notes:
\begin{itemize}
    \item We will create skip connections from the inputs to layers 2, 4, 6, and 8 to the outputs of layers 3, 5, 7, and 9, respectively.
    \item Skip connections with mismatched dimensions will be downsized using average pooling.
    \item The activation function for all convolutional layers will be ReLU.
    \item The output of the last average pooling layer will be a fully-connected layer with 2,048 neurons. These feed directly into the one-neuron output layer.
    \item The net will use a binary cross-entropy loss function.
    \item We will use the Adam optimizer with $\beta_1 = 0.9$ and $\beta_2=0.99$.
    \item We will train over 3,000 iterations.
    \item We will use learning rates of 0.01, 0.001, and 0.0001 for the first, second, and third sets of 1,000 training iterations, respectively.
\end{itemize}

\section{Ethical Considerations}
\label{ethical}

\subsection{Data Collection and Bias}
The implementation of AI-generated image detectors raises several ethical concerns, particularly regarding data collection and privacy. If the dataset used to train the detector contains personal or sensitive images, there is a risk of violating individuals' privacy rights. Additionally, the dataset may be biased, detecting AI-generated images only from certain architectures or sharing certain features while failing to generalize to others.

% Suggestion (Nathan): Maybe tie in better with data processing section? Ie. how will we do this
To minimize these risks, we ensure that our dataset is obtained from \textbf{peer-reviewed papers and licensed Kaggle datasets}. Furthermore, we use \textbf{balanced, diverse, and multi-source datasets} to reduce bias and avoid over-reliance on any single source. For further detail, see \ref{data_coll}.

\subsection{Misuse and Limitations}
The use of AI-generated image detectors also poses risks related to model accuracy and potential misuse. Due to the inherent uncertainty in AI models, achieving \textbf{perfect reliability} in distinguishing real and AI-generated images is generally infeasible, regardless of how well the model performs during testing. As a result, there is always a possibility of \textbf{false accusations}, where real images are mistakenly classified as AI-generated. The consequences of such misclassifications against legitimate artists might be severe and, in some cases, irreversible. To mitigate this, we will explicitly \textbf{disclaim that the model is not 100\% accurate} and should be \textbf{used with caution}. It is meant to assist rather than serve as final proof in any legal or professional decisions.

By taking these measures, we aim to ensure that our AI tool is ethically sound, responsibly deployed, and used within appropriate legal boundaries.

\section{Project Plan}
\label{plan}

Team communication will be crucial to our success. Our main channel of communication will be a \textbf{Whatsapp group chat}, which we have used thus far. We will meet once \textbf{every Sunday at 10am}, but should we need to meet more frequently, we will use our chat to determine meeting times on a rolling basis.

To ensure team cohesion and clear delineation of tasks, we will (a) assign specific tasks to each team member as explained in \ref{assigning_work} and (b) use Git for version control.

\subsection{Assigning Work}
\label{assigning_work}

For written deliverables, we will all brainstorm ideas for each section. However, to ensure that we do not overwrite each other's work, each team member will be responsible for drafting certain sections. The point total of one member's assigned sections should be similar to the totals of every other team member's assigned sections to \textbf{ensure equal work}. We will use \textbf{Git for version control} so that we can clearly see the contributions of each team member. Using LaTeX comments, our group chat, and verbal communication, we will notify each other of suggestions that we have for each other's work.

Regarding work on the project itself, we will equally delineate ``substantial tasks'' as described in the Project Final Report Handout and Rubric (see \ref{detailed_plan}). This we will ensure that we are not overwriting each other's work and that we each share an equal load of the total work. Like with written deliverables, we will use comments, our group chat, and verbal communication to share suggestions for each other's work.

\subsection{Detailed Plan}
\label{detailed_plan}

Table \ref{plan_table} shows our internal deadlines for various components of the project throughout the rest of the semester. Though we will each work on all aspects of the projects, each aspect will be spearheaded by certain group members.

Description of tasks:
\begin{itemize}
        \item \textbf{Data Collection \& Verification:} Make a final determination on data sources, and add to GitHub respository.
        \item \textbf{Data Preprocessing:}              Split data into five sets as described in \ref{data_mod}. Ensure similar semantic content between real and fake images. 
        \item \textbf{Baseline Model Implementation:}   Implement and train model detailed in \ref{baseline}. Ensure non-random performance.
        \item \textbf{Primary Model Design:}            Implement and begin training on both stages of the architecture propoposed in \ref{arch}. Ensure performance is at least as good as the baseline.
        \item \textbf{Primary Model Training \& Optimization:} Finish training the primary model over multiple hyperparameters, and select the best model based on validation data.
        \item \textbf{Primary Model Analysis:}          Perform qualitative and quantitative analysis of the model on test data. Compare the efficacy of this model to the baseline model.
\end{itemize}

    \begin{table}[t]
    \caption{Project internal deadlines.}
    \label{plan_table}
    \begin{center}
    \begin{tabular}{llll}
    \multicolumn{1}{c}{\bf Task}            & \multicolumn{1}{c}{\bf Internal Deadline} & \multicolumn{1}{c}{\bf Task Lead(s)} & \multicolumn{1}{c}{\bf Status}
    \\ \hline \\
    Data Collection \& Verification         & 02-23                                     & Paul \& Vedansh       & In progress \\
    Data Preprocessing                      & 03-01                                     & Paul \& Vedansh       & Not started \\
    Baseline Model Implementation           & 03-01                                     & Nathan \& Paul        & Not started \\                   
    Primary Model Design                    & 03-16                                     & Nathan \& William     & Not started  \\
    Primary Model Training \& Optimization  & 03-25                                     & Nathan \& William     & Not started  \\
    Primary Model Analysis                  & 03-30                                     & Vedansh \& William    & Not started  \\
    \end{tabular}
    \end{center}
    \end{table}
    
\section{Risk Register}
\label{risk}
% no deep fake
Creating a successful AI-generated image detection model involves various risks that would affect the project's success. This section highlights significant risks, evaluates their probability and effects, and presents detailed mitigation strategies.

\subsection{Insufficient Data Diversity}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} A lack of diverse training data can lead to a model that generalizes poorly to real-world scenarios, limiting its ability to detect AI generated fake images using different techniques or involving diverse demographics.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Data Augmentation:} Apply geometric transformations (e.g., rotation, scaling, flipping), color adjustments (e.g., brightness, contrast), and noise injection to artificially increase dataset variability \citep{shorten2019}. This will help the model adapt to various alterations typical in AI-generated images.
    \item \textbf{Continuous Data Acquisition:} Regularly update the dataset with newly generated AI images from emerging technologies to ensure that the model stays current and can detect the latest deep fake techniques.
\end{itemize}

\subsection{Prolonged Training Time}
\textbf{Likelihood:} High \\
\textbf{Impact:} Extended training times can delay project milestones, reduce iteration speed, and limit experimentation with different model architectures.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Transfer Learning:} Utilize pre-trained models like EfficientNet to reduce training time while maintaining high performance \citep{tan2019}. ResNet-based architectures, such as SRResNet, can enhance image resolution for better deep fake detection \citep{ledig2017}.
    \item \textbf{Cloud-Based GPU Resources:} Leverage high-performance computing resources through platforms such as Google Colab Pro, AWS SageMaker, and Microsoft Azure to accelerate training processes.
    \item \textbf{Optimized Code Practices:} Implement efficient data loading pipelines (using Optimized Data Storage), mixed-precision training (for weights and activations), and parallel processing to enhance computational efficiency.
\end{itemize}

\subsection{Overfitting}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} Overfitting results in a model that performs well on training data but poorly on unseen data, compromising its real-world effectiveness.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Regularization Techniques:} Apply dropout layers, L2 regularization, and batch normalization to prevent over-reliance on specific features \citep{srivastava2014}.
    \item \textbf{Cross-Validation:} Use k-fold cross-validation to ensure the model's robustness across different data splits, reducing the likelihood of overfitting to specific subsets.
    \item \textbf{Early Stopping:} Monitor validation loss during training and halt the process when performance plateaus or degrades, preventing unnecessary overfitting (stopping with patience).
\end{itemize}

\subsection{Technical Skill Gaps}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} Knowledge gaps in specific areas (e.g., advanced machine learning techniques, cloud computing) can slow down development and affect model performance.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Skill Development:} Leverage online courses (e.g., Coursera) and organize group study sessions to address specific knowledge gaps.
    \item \textbf{Mentorship:} Seek advice from professors, TAs, or online platforms like Stack Overflow and GitHub for problem-solving support.
    \item \textbf{Task Allocation:} Distribute tasks based on each team member's strengths to optimize efficiency and project quality.
    \item \textbf{Scoping:} If knowledge gaps are too large, refine the project scope to align with the team's current skill level, ensuring the project remains achievable within the timeline.
\end{itemize}

\subsection{Model Underperformance}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} An underperforming model may fail to detect fake AI generated images from real ones with high accuracy, reducing the system's reliability.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Architecture Refinement:} Experiment with different CNN architectures to optimize feature extraction from general images. Increase comlexity, number of layers, and number of parameters in the model.
    \item \textbf{Hyperparameter Tuning:} Use automated techniques like grid search, random search, or Bayesian optimization to fine-tune CNN parameters for optimal performance \citep{NIPS2011_86e8f7ab}.
\end{itemize}

\section{Link to GitHub and Google Colab}

The project's GitHub repository can be accessed at:  
\href{https://github.com/WilliamJWen/Project42}{https://github.com/WilliamJWen/Project42}

Our Google Colab notebook can be found in the GitHub Repo at path: ./colab_notebooks/model.ipynb. 
Alternate access at: \href{https://colab.research.google.com/github/WilliamJWen/Project42/blob/main/colab_notebooks/model.ipynb}{https://colab.research.google.com/github/WilliamJWen/Project42/blob/main/colab_notebooks/model.ipynb}

\label{last_page}

\bibliography{APS360_ref}
\bibliographystyle{iclr2022_conference}

\end{document}
