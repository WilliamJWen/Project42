\documentclass{article} % For LaTeX2e
\usepackage{iclr2022_conference,times}
\usepackage{graphicx}
\usepackage{hyperref}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

%######## APS360: Uncomment your submission name
\newcommand{\apsname}{Project Proposal}
%\newcommand{\apsname}{Progress Report}
%\newcommand{\apsname}{Final Report}

%######## APS360: Put your Group Number here
\newcommand{\gpnumber}{42}

\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}

%######## APS360: Put your project Title here
\title{Project Proposal}


%######## APS360: Put your names, student IDs and Emails here
\author{Vedansh Mehta  \\
Student\# 1008973577 \\
\texttt{vedansh.mehta@mail.utoronto.ca} \\
\And
Nathan Shreve  \\
Student\# 1004404487 \\
\texttt{n.shreve@mail.utoronto.ca} \\
\AND
William Wen  \\
Student\# 1007956650 \\
\texttt{jwilliam.wen@mail.utoronto.ca} \\
\And
Paul Zhao \\
Student\# 1009052276 \\
\texttt{paul.zhao@mail.utoronto.ca} \\
\AND
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\iclrfinalcopy 
%######## APS360: Document starts here
\begin{document}


\maketitle

\begin{abstract}
WRITE ABSTRACT HERE
%######## APS360: Do not change the next line. This shows your Main body page count.
----Total Pages: \pageref{last_page}
\end{abstract}



\section{Introduction}
\label{intro}
% Comments (Nathan):
% We decided not to use the term deep fake, right?
% We need citations for all our claims

The emergence of realistic AI image generation presents a significant challenge in the current digital landscape. This technology have evolved from simple image modifications to sophisticated videos that can convincingly mimic actual individuals. With tools like Generative Adversarial Networks (GANs) and Autoencoders, even non-experts can now generate convincing synthetic media. These modifications are often imperceptible from authentic content to those without specialized knowledge, posing substantial risks to societal trust, personal safety, and information integrity.

% Suggestion (Nathan):
% The emergence of realistic AI image generation presents a significant challenge in the current digital landscape. This technology has evolved from simple image modifications to sophisticated videos that can convincingly mimic real individuals. With tools like Generative Adversarial Networks (GANs) and Diffusion Models (DMs), even non-experts can now generate convincing synthetic media. These media are often imperceptible from authentic content, even to those with specialized knowledge, posing substantial risks to societal trust, personal safety, and information integrity. CITE ALL CLAIMS

\subsection{Motivation}
% Comment (Nathan): Cite, don't use "deep fake"
The rising prevalence of deep fakes presents serious threats to society. They have been used to spread misinformation, sway political debates, and jeopardize individual reputations. They have facilitated dishonest behaviors, ranging from impersonating executives for monetary scams to inflicting considerable psychological damage on victims of non-consensual deep fake pornography. Moreover, deep fakes blur the line between art made by humans and that produced by AI, challenging traditional concepts of authorship and artistic authenticity, presenting significant dangers to societal trust, individual safety, and the integrity of information.

\subsection{Goal}
The main aim of this project is to create a dependable model based on deep learning that can identify deep fake material. While this discussion emphasizes image-based deep fakes, the approach can be extended to video evaluation. 
This method aims to distinguish genuine real images from artificial ones with great precision, thereby aiding the larger initiative against digital misinformation. 

\subsection{Significance}
% Comment (Nathan): This feels like it's the same thing as the Motivation, just with different examples
The significance of this project is rooted in its possible uses across different fields, such as journalism, social media networks, and cybersecurity. With the rising accessibility of deep fake creation tools, the potential for their misuse increases. Creating efficient detection systems is vital not only for spotting counterfeit content but also for rebuilding public trust in digital media, thereby reducing misinformation. News agencies can employ detection tools to confirm the authenticity of content, whereas social media sites can utilize them to identify or eliminate altered content. Legal experts can utilize these tools for forensic inquiries, while cybersecurity frameworks can incorporate them to combat biometric spoofing threats.

\subsection{Justification for Employing Deep Learning}
% Comment (Nathan):
% Again, citations
% AI conflict?
% We say later that CNNs don't work all too well. You say that detection systems need to utilize recent developments to anticipate new threats -- (a) what does this mean?, (b) the point of doing zero-shot is that we don't have to continually adapt to new generative models coming out
% You talk about transfer learning but we aren't using that
The goal is to combat the AI conflict using AI. Deep learning, especially CNNs, is highly effective for the purpose of detecting deep fakes. Conventional detection techniques depend on manually crafted features, which frequently do not manage to grasp the subtle and complex artifacts created during deep fake production. Thus, detection systems need to be flexible, utilizing the most recent developments in machine learning to anticipate new threats—implying the application of Deep Learning techniques  sustaining their efficacy over time. Deep Learning methods (such as transfer learning) can be employed to improve model efficacy by utilizing pre-trained models on extensive datasets, minimizing the requirement for significant computational resources and training duration.

\section{Figure / Illustration}
\label{illustration}

Our proposed model follows a two-step training process, with the first stage exclusively trained on real images and the second stage incorporating both real and AI-generated images for classification.

\subsection{Step 1: Real Image Compression and Reconstruction}
% Comments (Nathan):
% The model doesn't learn to downscale the images, I think this is just done through average pooling
% Use \ref{}s to reference your figure
The first step involves training an image compression and reconstruction model solely on real images. The model learns to effectively downscale and reconstruct high-resolution images using convolutional layers (CNN) and pooling operations. Specifically:
\begin{itemize}
    \item Real high-resolution images are downscaled through pooling layers and passed through multiple CNN layers.
    \item The CNN extracts essential features and maps them to a latent space representation.
    \item A fully connected layer then predicts the \textbf{weight, mean, and scale} parameters for a logistic probability distribution, which is used to reconstruct the original high-resolution image.
    \item The objective of this step is to create a model capable of accurately compressing and decompressing real images while preserving their statistical properties.
\end{itemize}

\subsection{Step 2: Real vs. AI-Generated Image Classification}
% Suggestion (Nathan):
% For the "Image Statistics" box, maybe name it "Loss Statstics" and then have Entropy bubble, NLL, bubble, and then vertical ellipses underneath?
In the second step, the model is extended to classify images as real or AI-generated. This stage leverages both real and AI-generated datasets:
\begin{itemize}
    \item Input images, including both real and AI-generated high-resolution images, undergo the same compression and reconstruction process as in Step 1.
    \item The previously trained model is applied \textbf{only to real images} to ensure learned representations align with natural image statistics.
    \item Using the learned \textbf{mean, weight, and scale} parameters, the model computes entropy-based statistics such as \textbf{Negative Log-Likelihood (NLL) and entropy values} for each image.
    \item These computed statistics are then passed through multiple fully connected layers to classify whether an image is real or AI-generated.
\end{itemize}

By structuring the model in this two-step process, we ensure that the first stage learns an accurate representation of natural image statistics, which the second stage leverages to effectively detect synthetic images.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=\linewidth]{Fig/high_level_architecture.pdf}
    \caption{Two-step high level architecture for AI-generated image detection. Step 1 (top) trains a compression and reconstruction model (blue box) solely on real images, learning to restore downscaled high-resolution images using CNN layers and logistic probability distribution parameters. Step 2 (bottom) applies the trained model (blue box) to both real and AI-generated images, extracting entropy-based statistics such as Negative Log-Likelihood (NLL) and entropy values. These statistics are passed through multiple fully connected layers for final classification.}
\end{figure}

\section{Background \& Related Work}
\label{background}

Image synthesis is the process wherein an artificial image is generated by a computer from an input prompt, which may be text or some other form of media. This field exploded after the creation of Generative Adversarial Networks (GAN) in 2014, a deep learning architecture particularly adept at generating photorealistic images \citep{GANfather}. More recently, diffusion models (DM) have also been a popular choice for image synthesis \citep{latent-diffusion}. While many attempts have been made to develop programs that can detect images generated by these architectures, they continually evolve to outsmart old detectors.

\subsection{Sightengine}

There are a number of AI-generated image detection websites which are free to use. One of these is \citet{sightengine}, which has a high accuracy rate compared to many other websites: approximately 99\% on real images and 81\% on AI-generated ones \citep{li2024adversarialaiartunderstandinggeneration}. However, it is far from foolproof. For example, when tested on images generated from image prompts by Dream Studio and DALL-E, its accuracy falls to only 34\%. As opposed to images generated from text promts, images generated from real image prompts may be more challenging to detect, since they are more likely to be very similar to the real images they were generated from.

Many free websites like sightengine also predict the source of AI-generated images among many commonly-used synthesis models. Although the accuracy of this feature has not been formally investigated, it seems to fail often.

Though sightengine has not published its methods for AI-generated image detection, there are a number of open-source detectors available online, some of which are discussed below.

\subsection{Beyond the Spectrum}

Many earlier attempts at AI-generated image detection focused on GAN-generated images, since using DMs for image synthesis only began in 2022. One of these is Beyond the Spectrum (BtS), an open-source project \citep{he2021spectrumdetectingdeepfakesresynthesis}.

Its method for detection involves two stages. First, a re-synthesizer is trained, only on real images, to reconstruct images from their downsampled versions. Next, this re-synthesizer is given both real and fake images, and the reconstruction error (which is assumed to be greater for GAN-generated images) is given to a classifier to predict whether a given image is real or not.

In 2021, BtS achieved approxiately 90\% accuracy on its testing datasets and was state-of-the-art (SoTA). However, in 2024, after the progression of GAN models and the advent of DMs, BtS achieves only a 21\% accuracy rate \citep{li2024adversarialaiartunderstandinggeneration}. Nonetheless, its approach is echoed in more recent successful approaches, such as the zero-shot method discussed in \ref{ZED}.

\subsection{Contrastive Language–Image Pretraining}

Another architecture that has been explored for detecting AI-generated images is Contrastive Language–Image Pretraining (CLIP), which was developed by OpenAI in 2021 \citep{radford2021learningtransferablevisualmodels}. This model is trained on pairs of images and text, and in the context of AI-generated image detection, this text might either be their prompts or human-written descriptions. CLIP was used to achieve an accuracy of 95-100\%, making it a promising model for AI-generated image detection \citep{moskowitz2024detectingaigeneratedimagesclip}.

\subsection{Vision Transformers}

In natural language processing, text is interpreted as a sequence of tokens from which subsequent tokens can be predicted. Vision transformers (ViT) take a similar approach. Images are broken down into non-overlapping sections, like tokens, which are sent into an encoder comprised of multi-head attention and feed-forward neural networks. The output of the encoder is then passed into an MLP which classifies the image; in our case, it predicts whether the image is real or fake. In April 2024, researchers combined CLIP and ViT (CLIP-ViT) and were able to outperform a number of SoTA detection methods with an average accuracy of 90\% \citep{cozzolino2024raisingbaraigeneratedimage}.

\subsection{Zero-Shot Entropy-Based Detector}
\label{ZED}

The main issue in designing AI-generated image detectors is that image synthesis models are constantly evolving to circumvent detectors trained on old data. In September 2024, a new zero-shot method was devised which initally only trains on real images \citep{cozzolino2024zeroshotdetectionaigeneratedimages}. First, a CNN is trained to predict real images from encoded versions of those images. Next, the CNN is used to predict both real and fake images from their encoded versions, and loss statistics used to differentiate real images from synthetic ones. Higher loss generally corresponds to AI-generated images, since the CNN provides a good model for real images.

This method was able to achieve an accuracy of 90\%, better than many other SoTA models. However, one drawback is that training and testing datasets were comprised only of uncompressed images.

\section{Data Processing}
\label{data}
Our model involves two phases of training (see \ref{arch}). As such, we require five datasets: two training sets, two validation sets, and one testing set. The first phase is trained only on real images, meaning that one training set and one validation set will be comprised only of real images. For the other training and validation sets, it is crucial to process data in order to minimize bias. We have identified the most potentially impactful bias in our data as being the semantic content of the images.

\subsection{Data Collection}
% Suggestions (Nathan):
% Do the in-text citations for RAISE and Dresden
% "mentioned in detail later": reference the section
% Split into more paragraphs -> easier to read
% Create a table showing this information (sources, amounts, etc.) -> hard to keep track of numbers in sentences like this
To guarantee that the model is exposed to a diverse range of semantics, we will utilize two well-established camera-based digital forensics datasets: 1. RAISE: A Raw Images Dataset For Digital Image Forensics; 2.The 'Dresden Image Database' For Benchmarking Digital Image Forensics. These datasets collectively contain approximately 22,000 real images, captured under varying conditions and environments. The model will be trained in two phases which will be mentioned in detail later. For the first phase, 10,000 real images will be allocated for training and 2,000 real images for validation. For the second phase, 5,000 real images will be allocated for training and 1,000 images for validation. The remaining 2,000 real images will be reserved for evaluation in the testing phase. For the second phase, 5,000 synthetic images will also be used to training and 1,000 for validation which enables the model to develop a robust entropy-based understanding of real-world image statistics.
The testing dataset will be balanced, comprising 2,000 real images and 2,000 AI-generated images. The synthetic images will be sourced from the SyntheticEye AI-Generated Image Dataset [SyntheticEye Reference], which includes images produced by a range of state-of-the-art generative models, including Stable Diffusion, DALL·E, and others. Incorporating AI-generated images from multiple sources ensures that the testing conditions closely reflect real-world inputs, enhancing the model's ability to generalize across diverse synthetic image distributions.

\subsection{Data Modification}
For image inputs, the CNN requires a fixed resolution of 256×256 pixels. To ensure compatibility, all images in both the training and testing datasets will be cropped to 256×256 while preserving their essential features.
Additionally, to prevent any biases arising from variations in image attributes, all datasets will be normalized and standardized. This includes converting all images to RGB color space, ensuring uniform channel distributions across the dataset. Standardizing the color format enhances consistency in feature representation, improving the model's robustness and generalization.

\section{Architecture}
\label{arch}
\subsection{Motivation}

Nowadays, image classification models typically use Convolutional Neural Networks (CNN) as their base architecture. Classical CNNs will use datasets that consists of AI-generated images to train and learn special attributes about these artificial pictures. But inefficiencies in the training process of CNNs are starting to surface as more and more image generation models are being released. With more image generation models come different characteristics that the CNN classifier never learned. This leads towards a need for training with the new datasets which both takes time and money (Cozzolino et al. 2024).

% Suggestion (Nathan):
% Nowadays, image classification models typically use Convolutional Neural Networks (CNN) as their base architecture. Classical CNNs train on datasets of AI-generated images to learn special features that are otherwise undetectable. However, as more and more image generation models are released, these CNNs are routinely oustmarted. New image generation models carry new characteristics which the CNN never learned. This creates a need for further training with new datasets, which takes both time and money (Cozzolino et al. 2024) PROPER CITATION.

% Nathan:
% We shouldn't use the name "Zero-Shot Entropy Detector". that is the name of the project from the paper and we shouldn't copy that I don't think. We can just talk about (a) zero-shot method(s). Also, only the first stage is zero-shot, just to be clear
The Zero-Shot Entropy Detector (ZED) is unique in a way that its training process for detecting AI-generated images doesn't rely on synthetic data sets. The main idea behind ZED is to estimate how ``surprising'' an image is compared to the real images it trained on. It is assumed that real images follow a ``natural'' statistic pattern, while AI-generated images typically consists of ``unnatural'' statistical patterns that are detectable \citep{cozzolino2024zeroshotdetectionaigeneratedimages}.

% entropy and nll based, so maybe it's image statistic based?
% we did used ai images in the second step training
% I think we need to mention nll entropy is enough to detemine if a image is ai generated from the zed paper
% Nathan:
% instead of entropy-based i think we can say loss-based, since we might pick slightly different decision stats. also it might not be clear what entropy is
% Reference William's figures
\subsection{Architecture}
The architecture of our neural network consists of two phases: CNN training and entropy based classification. In the CNN, a real image is first fed into a CNN where a predicted representation of the image is outputted. The error between the predicted and expected output would be back propagated to adjust the weights and biases through the layers of neurons. After the CNN is trained, it will be connected to a classifier where entropy based loss would be used to predict whether an image is AI-generated or real. This approach allows for zero-shot generalization, meaning the system can detect new AI-generated images without explicit training on synthetic data.

% Suggested revision (Nathan):
% Training the architecture of our neural network consists of two phases: (1) CNN training and (2) loss-based classification.

% In stage (1), WILLIAM ADD HERE the downsized versions of real images are given to a CNN as inputs. The CNN will upscale these images and predict their original full-sized versions. The error between the predicted and expected output will be used to adjust the weights and biases of the CNN's filters through backpropagation. This stage is zero-shot, meaning it will not require retraining on synthetic data upon the advent of new image-generating AI models.

% In stage (2), we no longer train the CNN, and it will provide a good model for upscaling real images, but not AI-generated ones. In this stage, we will give the CNN both real and generated images. We will calculate loss statistics on its output, and use these statistics as the input to a classifier. SOME CONCLUSION HERE

\section{Baseline Model}
\label{baseline}

Our baseline model will mirror \citet{wang2020cnngeneratedimagessurprisinglyeasy}, an early attempt at AI-generated image detection. This model uses ResNet-50 trained on real images from ImageNet and fake images generated by three GAN architecures. We will expand our dataset to include fake images from a greater variety of image generators, including diffusion models (see \ref{data}). For simplicity, we will use a CNN but \textit{not} ResNet. Like \citet{wang2020cnngeneratedimagessurprisinglyeasy}, the classifier will use a binary cross-entropy loss function.
% EXPAND, MORE DETAIL

\section{Ethical Considerations}
\label{ethical}

\subsection{Data Collection and Bias}
The implementation of AI-generated image detectors raises several ethical concerns, particularly regarding data collection and privacy. If the dataset used to train the detector contains personal or sensitive images, there is a risk of violating individuals' privacy rights. Additionally, the dataset may be biased, detecting AI-generated images only from certain architectures or sharing certain features while failing to generalize to others.

% Suggestion (Nathan): Maybe tie in better with data processing section? Ie. how will we do this
To minimize these risks, we ensure that our dataset is obtained from \textbf{peer-reviewed papers and licensed Kaggle datasets}. Furthermore, we use \textbf{balanced, diverse, and multi-source datasets} to reduce bias and avoid over-reliance on any single source.

\subsection{Misuse and Limitations}
The use of AI-generated image detectors also poses risks related to model accuracy and potential misuse. Due to the inherent uncertainty in AI models, achieving \textbf{perfect reliability} in distinguishing real and AI-generated images is generally infeasible, regardless of how well the model performs during testing. As a result, there is always a possibility of \textbf{false accusations}, where real images are mistakenly classified as AI-generated. The consequences of such misclassifications against legitimate artists can be severe and, in some case, irreversible. To mitigate this, we will explicitly \textbf{disclaim that the model is not 100\% accurate} and should be \textbf{used with caution}. It is meant to assist rather than serve as final proof in any legal or professional decisions.

By taking these measures, we aim to ensure that our AI tool is ethically sound, responsibly deployed, and used within appropriate legal boundaries.


\section{Project Plan}
\label{plan}

Team communication will be crucial to our success. Our main channel of communication will be a Whatsapp group chat, which we have used thus far. We will meet once every Sunday at 10am, but should we need to meet more frequently, we will use our chat to determine meeting times on a rolling basis.

To ensure team cohesion and clear delineation of tasks, we will (a) assign specific tasks to each team member as explained in \ref{assigning_work} and (b) use Git for version control.

\subsection{Assigning Work}
\label{assigning_work}

For written deliverables, we will all brainstorm ideas for each section. However, to ensure that we do not overwrite each other's work, each team member will be responsible for drafting certain sections. The point total of one member's assigned sections should be similar to the totals of every other team member's assigned sections to ensure equal work. We will use Git for version control so that we can clearly see the contributions of each team member. Using LaTeX comments, our group chat, and verbal communication, we will notify each other of suggestions that we have for each other's work.

Regarding work on the project itself, we will equally delineate ``substantial tasks'' as described in the Project Final Report Handout and Rubric CITE (see \ref{detailed_plan}). This we will ensure that we are not overwriting each other's work and that we each share an equal load of the total work. Like with written deliverables, we will use comments, our group chat, and verbal communication to share suggestions for each other's work.

\subsubsection{Project Proposal}

Table \ref{project_proposal_table} shows who is responsible for drafting each section of the Project Proposal. Note that each member is assigned between 9 and 11 points.

    \begin{table}[t]
    \caption{Project Proposal task assignment and deadlines.}
    \label{project_proposal_table}
    \begin{center}
    \begin{tabular}{llll}
    \multicolumn{1}{c}{\bf Task}                    & \multicolumn{1}{c}{\bf Points} & \multicolumn{1}{c}{\bf Internal Deadline} & \multicolumn{1}{c}{\bf Assignee(s)}
    \\ \hline \\
    Introduction                                    & 4                              & 02-06                                     & Vedansh \\
    Creating Illustration/Figure                    & 4                              & 02-06                                     & William \\
    Background \& Related Work                      & 4                              & 02-06                                     & Nathan \\
    Data Processing                                 & 4                              & 02-06                                     & Paul \\
    Architecture                                    & 2                              & 02-06                                     & Paul \\
    Baseline Model                                  & 2                              & 02-06                                     & Paul \\
    Ethical Considerations                          & 2                              & 02-06                                     & William \\
    Risk Register                                   & 4                              & 02-06                                     & Vedansh \\
    Project Plan                                    & 4                              & 02-06                                     & Nathan \\
    GitHub \& Colab Repositories                    & 1                              & 02-06                                     & William \\
    Formatting References                           & 1                              & 02-06                                     & Nathan \\
    Proofreading (Structure, Grammar, Mechanics)    & 8                              & 02-06                                     & All Members \\
    \end{tabular}
    \end{center}
    \end{table}

\subsubsection{Detailed Plan}
\label{detailed_plan}

Table \ref{plan_table} shows our internal deadlines for various components of the project throughout the rest of the semester. Though we will each work on all aspects of the projects, each aspect will be spearheaded by certain group members.

    \begin{table}[t]
    \caption{Project internal deadlines.}
    \label{plan_table}
    \begin{center}
    \begin{tabular}{llll}
    \multicolumn{1}{c}{\bf Task}            & \multicolumn{1}{c}{\bf Internal Deadline} & \multicolumn{1}{c}{\bf Task Lead(s)}
    \\ \hline \\
    Data Collection \& Verification         & 02-23                                     & Paul \& Vedansh \\
    Data Preprocessing                      & 03-01                                     & Paul \& Vedansh \\
    Baseline Model Implementation           & 03-01                                     & Nathan \& Paul \\                   
    Primary Model Design                    & 03-16                                     & Nathan \& William \\
    Primary Model Training \& Optimization  & 03-25                                     & Nathan \& William \\
    Primary Model Analysis                  & 03-30                                     & Vedansh \& William \\
    \end{tabular}
    \end{center}
    \end{table}
    

\section{Risk Register}
\label{risk}
% no deep fake
Creating a successful deep fake detection model involves various risks that may affect the project's outcome. This section highlights significant risks, evaluates their probability and effects, and presents detailed mitigation strategies backed by pertinent research and industry best practices.

\subsection{Insufficient Data Diversity}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} A lack of diverse training data can lead to a model that generalizes poorly to real-world scenarios, limiting its ability to detect deep fakes generated using different techniques or involving diverse demographics.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Data Augmentation:} Apply geometric transformations (e.g., rotation, scaling, flipping), color adjustments (e.g., brightness, contrast), and noise injection to artificially increase dataset variability \citep{shorten2019}. This will help the model adapt to various alterations typical in AI-generated images.
    \item \textbf{Continuous Data Acquisition:} Regularly update the dataset with newly generated AI images from emerging technologies to ensure that the model stays current and can detect the latest deep fake techniques.
\end{itemize}

\subsection{Prolonged Training Time}
\textbf{Likelihood:} High \\
\textbf{Impact:} Extended training times can delay project milestones, reduce iteration speed, and limit experimentation with different model architectures.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Transfer Learning:} Utilize pre-trained models like EfficientNet to reduce training time while maintaining high performance \citep{tan2019}. ResNet-based architectures, such as SRResNet, can enhance image resolution for better deep fake detection \citep{ledig2017}.
    \item \textbf{Cloud-Based GPU Resources:} Leverage high-performance computing resources through platforms such as Google Colab Pro, AWS SageMaker, and Microsoft Azure to accelerate training processes.
    %\item \textbf{Optimized Code Practices:} Implement efficient data loading pipelines, mixed-precision training, and parallel processing to enhance computational efficiency.
\end{itemize}

\subsection{Overfitting}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} Overfitting results in a model that performs well on training data but poorly on unseen data, compromising its real-world effectiveness.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Regularization Techniques:} Apply dropout layers, L2 regularization, and batch normalization to prevent over-reliance on specific features \citep{srivastava2014}.
    \item \textbf{Cross-Validation:} Use k-fold cross-validation to ensure the model's robustness across different data splits, reducing the likelihood of overfitting to specific subsets.
    \item \textbf{Early Stopping:} Monitor validation loss during training and halt the process when performance plateaus or degrades, preventing unnecessary overfitting (stopping with patience).
\end{itemize}

\subsection{Technical Skill Gaps}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} Knowledge gaps in specific areas (e.g., advanced machine learning techniques, cloud computing) can slow down development and affect model performance.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Skill Development:} Leverage online courses (e.g., Coursera) and organize group study sessions to address specific knowledge gaps.
    \item \textbf{Mentorship:} Seek advice from professors, TAs, or online platforms like Stack Overflow and GitHub for problem-solving support.
    \item \textbf{Task Allocation:} Distribute tasks based on each team member's strengths to optimize efficiency and project quality.
    \item \textbf{Scoping:} If knowledge gaps are too large, refine the project scope to align with the team's current skill level, ensuring the project remains achievable within the timeline.
\end{itemize}

\subsection{Model Underperformance}
\textbf{Likelihood:} Moderate \\
\textbf{Impact:} An underperforming model may fail to detect deep fakes with high accuracy, reducing the system's reliability.

\textbf{Mitigation Strategies:}
\begin{itemize}
    \item \textbf{Architecture Refinement:} Experiment with different CNN architectures to optimize feature extraction from general images. Increase comlexity, number of layers, and number of parameters in our model.
    \item \textbf{Hyperparameter Tuning:} Use automated techniques like grid search, random search, or Bayesian optimization to fine-tune CNN parameters for optimal performance \citep{bergstra2011}.
\end{itemize}

\section{Link to GitHub}
The project's GitHub repository can be accessed at:  
\href{https://github.com/WilliamJWen/Project42}{https://github.com/WilliamJWen/Project42}


\label{last_page}

\bibliography{APS360_ref}
\bibliographystyle{iclr2022_conference}

\end{document}
